# ğŸ’° Dashboard Financeiro Pessoal

> AnÃ¡lise inteligente de extratos bancÃ¡rios OFX com categorizaÃ§Ã£o automÃ¡tica usando LLM local

[![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.29+-red?logo=streamlit)](https://streamlit.io/)
[![Ollama](https://img.shields.io/badge/Ollama-LLM%20Local-green)](https://ollama.ai/)

---

## ğŸŒŸ CaracterÃ­sticas Principais

- âœ… **Leitura de OFX** - Importa extratos bancÃ¡rios de qualquer banco brasileiro
- âœ… **CategorizaÃ§Ã£o Inteligente** - LLM local analisa e categoriza cada transaÃ§Ã£o
- âœ… **Aprendizado de PadrÃµes** - Sistema aprende com suas transaÃ§Ãµes para categorizar mais rÃ¡pido
- âœ… **VisualizaÃ§Ãµes Interativas** - GrÃ¡ficos de pizza, barras, tendÃªncias mensais
- âœ… **AnÃ¡lises Detalhadas** - Top despesas, receitas, resumos por categoria
- âœ… **Filtros AvanÃ§ados** - Por categoria, tipo, perÃ­odo
- âœ… **Export CSV** - Exporte dados para anÃ¡lises externas
- âœ… **100% Local e Privado** - Seus dados nÃ£o saem do seu computador

---

## ğŸ“‹ Ãndice

1. [PrÃ©-requisitos](#-prÃ©-requisitos)
2. [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
3. [Como Usar](#-como-usar)
4. [Estrutura do Projeto](#-estrutura-do-projeto)
5. [ConfiguraÃ§Ã£o do Ollama](#-configuraÃ§Ã£o-do-ollama)
6. [Categorias DisponÃ­veis](#-categorias-disponÃ­veis)
7. [Comandos Ãšteis](#-comandos-Ãºteis)
8. [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)

---

## ğŸ“‹ PrÃ©-requisitos

### Software NecessÃ¡rio

| Software | VersÃ£o | Download | Verificar |
|----------|--------|----------|-----------|
| **Python** | 3.8+ | [python.org](https://www.python.org/downloads/) | `python --version` |
| **Ollama** | Latest | [ollama.ai](https://ollama.ai/) | `ollama --version` |
| **pip** | Latest | (incluÃ­do com Python) | `pip --version` |

### Instalar Ollama

**Windows:**
```powershell
# Baixar instalador em https://ollama.ai/download/windows
# Executar o instalador
# Verificar instalaÃ§Ã£o
ollama --version
```

**macOS:**
```bash
# Baixar instalador em https://ollama.ai/download/mac
# Ou via Homebrew
brew install ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Baixar Modelo LLM

ApÃ³s instalar Ollama, baixe um modelo:

```bash
# Modelo recomendado (leve e rÃ¡pido)
ollama pull llama3.2

# Alternativas
ollama pull llama2      # Modelo maior, mais preciso
ollama pull mistral     # Bom equilÃ­brio
ollama pull phi         # Muito leve
```

---

## ğŸš€ InstalaÃ§Ã£o

### Passo 1: Clone ou Baixe o Projeto

```bash
# Se estiver no repositÃ³rio do blog
cd financial-dashboard

# Ou navegue atÃ© a pasta
cd c:\Users\jorda\OneDrive\Documentos\Projeto - Blog\financial-dashboard
```

### Passo 2: Crie Ambiente Virtual (Recomendado)

**Windows:**
```powershell
python -m venv venv
venv\Scripts\activate
```

**macOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Passo 3: Instale DependÃªncias

```bash
pip install -r requirements.txt
```

**DependÃªncias instaladas:**
- `streamlit` - Interface web
- `pandas` - ManipulaÃ§Ã£o de dados
- `ofxparse` - Leitura de arquivos OFX
- `ollama` - IntegraÃ§Ã£o com LLM local
- `plotly` - GrÃ¡ficos interativos

---

## ğŸ’» Como Usar

### Passo 1: Iniciar Ollama (se nÃ£o estiver rodando)

```bash
# Em um terminal separado
ollama serve
```

### Passo 2: Executar o Dashboard

```bash
streamlit run app.py
```

O dashboard abrirÃ¡ automaticamente em: **http://localhost:8501**

### Passo 3: Fazer Upload do Extrato

1. **Obter extrato OFX do seu banco:**
   - Acesse o site ou app do banco
   - VÃ¡ em "Extratos" ou "Exportar"
   - Escolha formato **OFX** ou **Money** (sÃ£o equivalentes)
   - Baixe o arquivo

2. **Fazer upload no dashboard:**
   - Na barra lateral, clique em "Browse files"
   - Selecione o arquivo `.ofx` baixado
   - Aguarde o processamento

### Passo 4: Categorizar TransaÃ§Ãµes

1. ApÃ³s o upload, clique em **"ğŸ¤– Categorizar com LLM"**
2. Aguarde enquanto o LLM analisa cada transaÃ§Ã£o
3. O sistema aprenderÃ¡ padrÃµes automaticamente

### Passo 5: Explorar AnÃ¡lises

- **VisÃ£o Geral:** GrÃ¡ficos de pizza, barras e tendÃªncias
- **TransaÃ§Ãµes:** Lista completa com filtros
- **AnÃ¡lises:** Top despesas/receitas, resumos
- **ConfiguraÃ§Ãµes:** PadrÃµes aprendidos, exports

---

## ğŸ“‚ Estrutura do Projeto

```
financial-dashboard/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                      # AplicaÃ§Ã£o Streamlit principal
â”œâ”€â”€ ğŸ“„ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ README.md                   # Esta documentaÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸ“ utils/                      # UtilitÃ¡rios
â”‚   â””â”€â”€ ofx_parser.py             # Parser de arquivos OFX
â”‚
â”œâ”€â”€ ğŸ“ models/                     # Modelos de IA
â”‚   â””â”€â”€ categorizer.py            # Categorizador com LLM
â”‚
â””â”€â”€ ğŸ“ data/                       # Dados persistidos
    â””â”€â”€ learned_patterns.json     # PadrÃµes aprendidos (gerado automaticamente)
```

### DescriÃ§Ã£o dos Arquivos

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `app.py` | Interface Streamlit com dashboard completo |
| `utils/ofx_parser.py` | LÃª e processa arquivos OFX de bancos |
| `models/categorizer.py` | Categoriza transaÃ§Ãµes usando Ollama (LLM local) |
| `data/learned_patterns.json` | Cache de padrÃµes aprendidos para categorizaÃ§Ã£o rÃ¡pida |

---

## ğŸ¤– ConfiguraÃ§Ã£o do Ollama

### Modelos DisponÃ­veis

O dashboard suporta vÃ¡rios modelos Ollama:

| Modelo | Tamanho | RAM NecessÃ¡ria | Velocidade | PrecisÃ£o |
|--------|---------|----------------|------------|----------|
| **llama3.2** â­ | 2GB | 4GB | RÃ¡pido | Alta |
| **mistral** | 4GB | 8GB | MÃ©dio | Muito Alta |
| **llama2** | 7GB | 16GB | Lento | Excelente |
| **phi** | 1.5GB | 3GB | Muito RÃ¡pido | Boa |

**RecomendaÃ§Ã£o:** Use `llama3.2` para melhor equilÃ­brio.

### Instalar Modelo

```bash
# Modelo recomendado
ollama pull llama3.2

# Listar modelos instalados
ollama list

# Testar modelo
ollama run llama3.2
```

### Trocar Modelo no Dashboard

1. Na barra lateral, use o seletor "Modelo LLM"
2. Escolha o modelo desejado
3. Categorize novamente

---

## ğŸ·ï¸ Categorias DisponÃ­veis

O sistema categoriza automaticamente em:

| Categoria | Exemplos de TransaÃ§Ãµes |
|-----------|------------------------|
| **AlimentaÃ§Ã£o** | Supermercado, restaurante, iFood, padaria |
| **Transporte** | Uber, 99, gasolina, estacionamento, pedÃ¡gio |
| **Moradia** | Aluguel, condomÃ­nio, IPTU, Ã¡gua, luz, internet |
| **SaÃºde** | FarmÃ¡cia, mÃ©dico, plano de saÃºde, dentista |
| **EducaÃ§Ã£o** | Escola, faculdade, cursos, livros |
| **Lazer** | Cinema, Netflix, Spotify, academia, viagens |
| **VestuÃ¡rio** | Roupas, calÃ§ados, shopping |
| **ServiÃ§os** | Cabeleireiro, barbeiro, lavanderia |
| **Investimentos** | AplicaÃ§Ãµes, poupanÃ§a, CDB, aÃ§Ãµes |
| **Receitas** | SalÃ¡rio, freelance, vendas, reembolsos |
| **TransferÃªncias** | PIX, TED, DOC |
| **Outros** | TransaÃ§Ãµes nÃ£o categorizadas |

### Aprendizado de PadrÃµes

O sistema aprende automaticamente:
- âœ… ApÃ³s categorizar, salva padrÃµes em `data/learned_patterns.json`
- âœ… PrÃ³ximas transaÃ§Ãµes similares sÃ£o categorizadas instantaneamente
- âœ… PadrÃµes podem ser limpos em **ConfiguraÃ§Ãµes â†’ Limpar PadrÃµes**

---

## ğŸ”§ Comandos Ãšteis

### Executar Dashboard

```bash
# Modo normal
streamlit run app.py

# Modo com porta customizada
streamlit run app.py --server.port 8502

# Modo sem auto-reload
streamlit run app.py --server.runOnSave false
```

### Gerenciar Ollama

```bash
# Iniciar servidor Ollama
ollama serve

# Listar modelos instalados
ollama list

# Baixar novo modelo
ollama pull llama3.2

# Remover modelo
ollama rm llama2

# Testar modelo interativamente
ollama run llama3.2
```

### Gerenciar Ambiente Python

```bash
# Ativar ambiente virtual
venv\Scripts\activate  # Windows
source venv/bin/activate  # macOS/Linux

# Instalar/atualizar dependÃªncias
pip install -r requirements.txt

# Listar pacotes instalados
pip list

# Desativar ambiente
deactivate
```

---

## ğŸ› SoluÃ§Ã£o de Problemas

### Ollama nÃ£o estÃ¡ disponÃ­vel

**Erro:** `Ollama nÃ£o estÃ¡ rodando`

**SoluÃ§Ã£o:**
```bash
# Abra um novo terminal e execute
ollama serve

# Deixe rodando em background
```

---

### Modelo nÃ£o encontrado

**Erro:** `model 'llama3.2' not found`

**SoluÃ§Ã£o:**
```bash
# Baixar modelo
ollama pull llama3.2

# Verificar se foi instalado
ollama list
```

---

### Erro ao processar OFX

**Erro:** `Erro ao processar arquivo OFX`

**PossÃ­veis causas:**
1. Arquivo corrompido ou formato invÃ¡lido
2. Banco usa formato OFX nÃ£o padrÃ£o

**SoluÃ§Ã£o:**
- Baixe novamente o extrato do banco
- Certifique-se de escolher formato **OFX** ou **Money**
- Tente com um perÃ­odo menor (ex: 1 mÃªs)

---

### CategorizaÃ§Ã£o muito lenta

**Causa:** Modelo LLM muito pesado para seu hardware

**SoluÃ§Ã£o:**
```bash
# Usar modelo mais leve
ollama pull phi

# No dashboard, selecione "phi" no seletor de modelo
```

---

### PadrÃµes nÃ£o estÃ£o sendo salvos

**Causa:** PermissÃµes de escrita na pasta `data/`

**SoluÃ§Ã£o:**
```bash
# Criar pasta manualmente
mkdir data

# Dar permissÃµes (Linux/macOS)
chmod 755 data
```

---

## ğŸ“Š Exemplos de Uso

### AnÃ¡lise Mensal

1. FaÃ§a upload do extrato de 1 mÃªs
2. Categorize com LLM
3. VÃ¡ em **VisÃ£o Geral** â†’ veja grÃ¡fico de tendÃªncia mensal
4. Compare receitas vs despesas

### Identificar Maiores Gastos

1. VÃ¡ em **AnÃ¡lises**
2. Veja **Top 10 Maiores Despesas**
3. Identifique onde estÃ¡ gastando mais
4. Ajuste seus hÃ¡bitos

### Exportar para Excel

1. VÃ¡ em **TransaÃ§Ãµes**
2. Aplique filtros desejados
3. Clique em **ğŸ“¥ Download CSV**
4. Abra no Excel para anÃ¡lises customizadas

### Comparar Categorias

1. VÃ¡ em **VisÃ£o Geral**
2. Veja grÃ¡fico de pizza
3. Identifique categorias que mais pesam
4. Planeje cortes ou ajustes

---

## ğŸ¯ PrÃ³ximas Funcionalidades

- [ ] Suporte a mÃºltiplos arquivos OFX simultÃ¢neos
- [ ] ComparaÃ§Ã£o entre meses/perÃ­odos
- [ ] Alertas de gastos acima da mÃ©dia
- [ ] OrÃ§amento por categoria
- [ ] PrevisÃ£o de gastos futuros com ML
- [ ] Export para PDF com relatÃ³rios
- [ ] SincronizaÃ§Ã£o automÃ¡tica com bancos (Open Banking)
- [ ] App mobile (PWA)

---

## ğŸ”’ Privacidade e SeguranÃ§a

- âœ… **100% Local:** Todos os dados ficam no seu computador
- âœ… **Sem Internet:** LLM roda localmente via Ollama
- âœ… **Sem Cadastro:** NÃ£o precisa criar conta
- âœ… **Sem Uploads Externos:** Arquivos OFX nÃ£o saem da sua mÃ¡quina
- âœ… **Open Source:** CÃ³digo totalmente auditÃ¡vel

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ disponÃ­vel sob a licenÃ§a **MIT**.

---

## ğŸ‘¨â€ğŸ’» Autor

**Jordan Arruda**  
- GitHub: [@Juerda](https://github.com/Juerda)
- Blog: [blog-dados.vercel.app](https://blog-dados.vercel.app)

---

## ğŸ™ Agradecimentos

- **Ollama** - Por tornar LLMs locais tÃ£o fÃ¡ceis
- **Streamlit** - Pela framework web incrÃ­vel
- **ofxparse** - Pela biblioteca de parsing OFX
- **Plotly** - Pelos grÃ¡ficos interativos

---

## ğŸ†˜ Suporte

Encontrou um problema ou tem uma sugestÃ£o?

- ğŸ› **Bug:** Abra uma issue no GitHub
- ğŸ’¡ **SugestÃ£o:** Abra uma discussion no GitHub
- ğŸ“§ **Contato:** jordansales.arruda@gmail.com

---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela! â­**

**ğŸ’° Desenvolvido com â¤ï¸ para controle financeiro pessoal ğŸ’°**

---

*Ãšltima atualizaÃ§Ã£o: Dezembro 2025*

</div>
